version: '3'

name: "${PROJ_NAME}"
services:
  cardano-node:
    image: cardanocommunity/cardano-node:latest
    init: true
    hostname: cardano-node
    environment:
      NETWORK: ${NETWORK}
      SOCKET: "${CNODE_HOME}/sockets/node.socket" 
      UPDATE_CHECK: "N"
    volumes:
      - node-db:/opt/cardano/cnode/db
      - node-ipc:/opt/cardano/cnode/sockets
      - node-cfg:/opt/cardano/cnode/priv/files
      - ./scripts/:/scripts/
    entrypoint: >
      /bin/sh -c "
      echo 'Exporting node config files into node-cfg volume...' ;
      cp /opt/cardano/cnode/files/* /opt/cardano/cnode/priv/files/* ;
      ./entrypoint.sh ;
      "
    restart: on-failure
    healthcheck:
      test: ["CMD-SHELL", "netstat -ntlp | grep 12798"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "200k"
        max-file: "10"

  cardano-db-sync:
    image: ghcr.io/intersectmbo/cardano-db-sync:sancho-3-0-0
    hostname: cardano-db-sync
    environment:
      DISABLE_LEDGER: ${DISABLE_LEDGER}
      NETWORK: ${NETWORK:-mainnet}
      POSTGRES_HOST: postgress
      POSTGRES_PORT: ${POSTGRES_PORT}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      RESTORE_SNAPSHOT: ${RESTORE_SNAPSHOT:-}
      RESTORE_RECREATE_DB: N
      EXTRA_DB_SYNC_ARGS: ${EXTRA_DB_SYNC_ARGS:-}
    healthcheck:
      test: ["CMD-SHELL", "/scripts/lib/dbsync_healthcheck.sh"]
      interval: 60s
      timeout: 10s
    depends_on:
      # Depend on both services to be healthy before starting.
      cardano-node:
        condition: service_healthy
      postgress:
        condition: service_healthy
    volumes:
      - db-sync-data:/var/lib/cexplorer
      - node-ipc:/node-ipc
      - ./scripts/:/scripts/
    restart: on-failure
    logging:
      driver: "json-file"
      options:
        max-size: "200k"
        max-file: "10"

  # TODO: add http backend ogmios and it's entry on /configs/haproxy/haproxy.cfg
  ogmios:
    image: cardanosolutions/ogmios:${OGMIOS_VERSION:-latest}
    restart: on-failure
    command: [
      "--host", "0.0.0.0",
      "--node-socket", "/ipc/node.socket",
      "--node-config", "/opt/cardano/cnode/files/config.json"
    ]
    volumes:
      # exported automagically from cardano-node
      - node-cfg:/opt/cardano/cnode/files/
      - node-ipc:/ipc
    ports:
      - ${OGMIOS_PORT:-1337}:1337
    depends_on:
      cardano-node:
        condition: service_healthy


  postgress:
    image: postgres:16.1-bullseye
    hostname: postgress
    volumes:
      - postgresdb:/var/lib/postgresql/data
      - ./scripts/:/scripts/
    # ports:
    #   - "${POSTGRES_PORT}:${POSTGRES_PORT}"
    environment:
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_DB: ${POSTGRES_DB}
      RPC_SCHEMA: ${RPC_SCHEMA}
    healthcheck:
      test:  ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 60s
      timeout: 5s
    command: postgres -c max_connections=200 -c wal_level=minimal -c max_wal_senders=0 -c synchronous_commit=off
    restart: on-failure
    logging:
      driver: "json-file"
      options:
        max-size: "200k"
        max-file: "10"

  postgrest:
    image: postgrest/postgrest:v12.0.2
    hostname: postgrest
    depends_on:
      - postgress
    ports:
      - 8050:8050
    volumes:
      - ./scripts/:/scripts/
    environment:
      PGRST_DB_URI: postgres://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgress:${POSTGRES_PORT}/${POSTGRES_DB}
      PGRST_DB_ANON_ROLE: ${PGRST_DB_ANON_ROLE}
      #PGRST_DB_SCHEMA: ${RPC_SCHEMA}
      PGRST_DB_SCHEMAS: "${RPC_SCHEMA}, public, pg_catalog" # first one is default
      PGRST_SERVER_PORT: 8050
      PGRST_OPENAPI_SERVER_PROXY_URI: http://0.0.0.0:8050
      PGRST_DB_MAX_ROWS: 1000
      PGRST_DB_AGGREGATES_ENABLED: true
      PGRST_DB_EXTRA_SEARCH_PATH: "${RPC_SCHEMA}, public"
    restart: on-failure
    logging:
      driver: "json-file"
      options:
        max-size: "200k"
        max-file: "10"

  unimatrix:
    image: unimatrix-peer:latest
    build:
      context: ./src/unimatrix
    restart: always
    environment:
      - UNIMATRIX_PORT:${UNIMATRIX_PORT:-8765}
    # static http server can be exposed as well
    ports:
      - ${UNIMATRIX_PORT:-8765}:8765
    # TODO: fix env vars passing and link to persistent volume
    volumes:
      - unimatrix-data:/work/data


  portainer-agent:
    image: portainer/agent:latest
    environment:
      AGENT_CLUSTER_ADDR: portainer-agent
      AGENT_PORT: 9001
      LOG_LEVEL: DEBUG
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /var/lib/docker/volumes:/var/lib/docker/volumes

  portainer:
    image: portainer/portainer-ce:latest
    command: -H tcp://portainer-agent:9001 --tlsskipverify
    ports:
      - 9443:9443
      - 8000:8000
    volumes:
      - portainer-data:/data
      - /var/run/docker.sock:/var/run/docker.sock
    restart: unless-stopped
    depends_on:
      - portainer-agent

  # Develpoment and Testing
  swagger:
    image: swaggerapi/swagger-ui
    ports:
      - "8080:8080"
    expose:
      - "8080"
    environment:
      API_URL: http://127.0.0.1:8050/



  pgadmin:
    image: dpage/pgadmin4
    restart: always
    environment:
        PGADMIN_DEFAULT_EMAIL: ${PGADMIN_DEFAULT_EMAIL}
        PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_DEFAULT_PASSWORD}
        PGADMIN_LISTEN_PORT: 80
    ports:
        - "${PGADMIN_LISTEN_PORT:-5050}:80"
    links:
        - "postgress:pgsql-server"
    volumes:
        - pgadmin-data:/var/lib/pgadmin
    # not supported until docker compose 2.23.1
    # configs:
    #   - source: pgadmin_server
    #     target: /var/lib/pgadmin/servers.json
    entrypoint: >
      /bin/sh -c "
      EMAIL_SANITIZED=$$(echo \"$PGADMIN_DEFAULT_EMAIL\" | tr @ _)
      mkdir -p /var/lib/pgadmin/storage/${EMAIL_SANITIZED} ;
      PGADMIN_SERVER_JSON_FILE=/var/lib/pgadmin/storage/servers.json ;
      PGADMIN_PASSWORD_FILE=/var/lib/pgadmin/storage/${EMAIL_SANITIZED}/pgpass ;
      rm -rf $$PGADMIN_PASSWORD_FILE ;
      rm -rf $$PGADMIN_SERVER_JSON_FILE ;
      echo '${PGADMIN_DEFAULT_PASSWORD}' > $$PGADMIN_PASSWORD_FILE ;
      echo '{\"Servers\": {\"1\": { \"Group\": \"Servers\", \"Name\": \"${NETWORK}\", \"Host\": \"${PROJ_NAME}-postgres-1\", \"Port\": ${POSTGRES_PORT}, \"MaintenanceDB\": \"${POSTGRES_DB}\",  \"Username\": \"${POSTGRES_USER}\",  \"ConnectionParameters\": {  \"sslmode\": \"prefer\", \"connect_timeout\": 10, \"passfile\": \"/var/lib/pgadmin/storage/$EMAIL_SANITIZED/pgpass\" } }}}' > $$PGADMIN_SERVER_JSON_FILE ;
      chmod 600 $$PGADMIN_PASSWORD_FILE ;
      chmod 600 $$PGADMIN_SERVER_JSON_FILE ;
      echo 'Default Config file' ;
      cat $$PGADMIN_SERVER_JSON_FILE ;
      PGADMIN_SERVER_JSON_FILE=$$PGADMIN_SERVER_JSON_FILE /entrypoint.sh;
      "
    depends_on:
      postgress:
        condition: service_healthy


  haproxy:
    image: haproxy:2.9.0-bookworm
    hostname: haproxy
    depends_on:
      - postgrest
    volumes:
      - ./configs/haproxy/:/usr/local/etc/haproxy/
      - ./scripts/:/scripts/
    ports:
      - 8053:8053
    healthcheck:
      test: ["CMD-SHELL", "haproxy -c -- /usr/local/etc/haproxy/haproxy.cfg"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: on-failure
    logging:
      driver: "json-file"
      options:
        max-size: "200k"
        max-file: "10"

  cron:
    build: .
    environment:
      NETWORK: ${NETWORK:-mainnet}
      POSTGRES_HOST: postgress
      POSTGRES_PORT: ${POSTGRES_PORT}
      PGDATABASE: ${POSTGRES_DB}
      PGUSER: ${POSTGRES_USER}
      PGPASSWORD: ${POSTGRES_PASSWORD}
      RPC_SCHEMA: ${RPC_SCHEMA}
    volumes:
      - ./scripts/cron:/etc/cron.d/
      - ./scripts:/scripts
    # Uncomment for persistent logs
    # - ./logs:/var/log
    restart: unless-stopped

# not supported until docker compose 2.23.1
# configs:
#   pgadmin_server:
#     environment: PGADMIN_SERVER
#     content: '{"Servers": {"1": { "Group": "Servers", "Name": "${NETWORK}", "Host": "${PROJ_NAME}-postgres-1", "Port": ${POSTGRES_PORT}, "MaintenanceDB": "${POSTGRES_DB}",  "Username": ${POSTGRES_USER},  "ConnectionParameters": {  "sslmode": "prefer", "connect_timeout": 10, "passfile": "/pgpass" } }}}'

volumes:
  node-db:
  node-ipc:
  node-cfg:
  db-sync-data:
  postgresdb:
  portainer-data:
  pgadmin-data:
  unimatrix-data: